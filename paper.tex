\documentclass[twocolumn,superscriptaddress,aps]{revtex4-1}

\usepackage[utf8]{inputenc}

\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}

\usepackage{bm}
\usepackage{cancel}
\usepackage{bbold}
\usepackage{slashed}
\usepackage{graphicx}
\usepackage{color}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tikz}

\newcommand{\glnote}[1]{\textcolor{red}{[GL: #1]}}
\newcommand{\kcnote}[1]{\textcolor{red}{[KC: #1]}}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}

\begin{document}


% ==============================================================================

\title{\Large{Adversarial Variational Optimization of Non-Differentiable Simulators}}
\vspace{1cm}
\author{\small{\bf Gilles Louppe}\thanks{\texttt{g.louppe@nyu.edu}}}
\affiliation{New York University}
\author{\small{\bf Kyle Cranmer}\thanks{\texttt{kyle.cranmer@nyu.edu}}}
\affiliation{New York University}

\begin{abstract}

In this note, ... \glnote{todo.}


\end{abstract}

\maketitle

% ==============================================================================

\section{Introduction}

\glnote{Prescribed vs. implicit. See case of non-diff models in Balaji et al.}


% ==============================================================================

\section{Problem statement}

We consider a family of parameterized densities $p_\mathbf{\theta}(\mathbf{x})$
defined implicitly through the simulation of a stochastic generative
process, where $\mathbf{x} \in \mathbb{R}^d$ is the data and
$\mathbf{\theta}$ are the parameters of interest. The simulation may involve
some complicated latent process, such that
\begin{equation}\label{eqn:p_x}
    p_\mathbf{\theta}(\mathbf{x}) = \int p_\mathbf{\theta}(\mathbf{x}|\mathbf{z}) p(\mathbf{z}) d\mathbf{z}
\end{equation}
where $\mathbf{z} \in \mathbb{R}^m$ is a latent variable providing an external source
of randomness.

We assume that we already have an accurate simulation of the stochastic generative process
that defines $p_\mathbf{\theta}(\mathbf{x}|\mathbf{z})$, as specified through a deterministic function $g(\cdot;
\theta) : \mathbb{R}^m \to \mathbb{R}^d$. That is,
\begin{equation}\label{eqn:p_x_sim}
    p_\mathbf{\theta}(\mathbf{x}) = \frac{\partial}{\partial x_1} \dots \frac{\partial}{\partial x_d} \int_{\{\mathbf{z}:g(\mathbf{z};\mathbf{\theta}) \leq \mathbf{x}\}} p(\mathbf{z}) d\mathbf{z}.
\end{equation}
The simulator $g$ is assumed to be a non-invertible function, that can
only be used to generate data in forward mode.
For this reason, evaluating the integral in Eqn.~\ref{eqn:p_x_sim} is intractable.
Importantly, and as increasingly found in science, we consider the additional constraint that $g$ is a non-differentiable
model, e.g. when specified as a computer program.

Given some observed data $\{ \mathbf{x}_i | i=1, \dots, N \}$ drawn from the (unknown) true distribution $p_r$, our goal is the inference
of the parameters of interest $\mathbf{\theta}^*$ that minimize the divergence
between $p_r$ and the modeled
data distribution $p_\mathbf{\theta}$ induced by $g(\cdot; \mathbf{\theta})$. That is,
\begin{equation}
    \mathbf{\theta}^* = \arg \min_\mathbf{\theta} \rho(p_r, p_\mathbf{\theta}),
\end{equation}
where $\rho$ is some distance or divergence.


% ==============================================================================

\section{Background}

\subsection{Generative adversarial networks}

Generative adversarial networks (GAN) were first proposed by
\cite{goodfellow2014generative} as a way to build an implicit generative model
capable of producing samples from random noise $\mathbf{z}$. More specifically,
a generative model $g(\cdot; \mathbf{\theta})$ is pit against an adversarial
network $d$ whose antigonistic objective is to recognize real data $\mathbf{x}$
from generated data $g(\mathbf{z}; \mathbf{\theta})$. Both models $g$ and $d$
are trained simultaneously, in such a way that $g$ learns to maximally confuse
its adversary $d$ (which happens when $g$ produces samples comparable to the
observed data), while $d$ continuously adapts to changes in $g$. When $d$ is
trained to optimality before each parameter update of the generator, it can
be shown that the original adversarial learning procedure amounts to minimizing
the Jensen-Shannon divergence between $p_r$ and $p_\theta$.

More recently, ...

\glnote{Explain WGAN, loss and optimum.}

\subsection{Variational optimization}


% ==============================================================================

\section{Adversarial variational optimization}


% ==============================================================================

\section{Experiments}

\subsection{Toy problem}

\subsection{Physics example}


% ==============================================================================

\section{Related works}


\glnote{Implicit generative models.}
\glnote{ABC.}
\glnote{carl~\citep{cranmer2015approximating}.}
\glnote{Wood's papers.}
\glnote{CMA-ES.}


% ==============================================================================

\section{Summary}



% ==============================================================================

\section*{Acknowledgments}

GL and KL are both supported through NSF ACI-1450310, additionally KC is
supported through PHY-1505463 and PHY-1205376.


% ==============================================================================

\bibliographystyle{acm}
\bibliography{bibliography.bib}


\end{document}
